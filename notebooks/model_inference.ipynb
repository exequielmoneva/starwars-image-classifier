{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8efe0974-4770-4c87-9848-21f3a1d1e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c550d92-ddc2-474a-add5-326547c1f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the categories that the model knows in the same order that were feed at training.\n",
    "class_names = ['Admiral Ackbar',\n",
    " 'Admiral Piett',\n",
    " 'Anakin Skywalker',\n",
    " 'BB-8',\n",
    " 'Bail Organa',\n",
    " 'Bib Fortuna',\n",
    " 'Boba Fett',\n",
    " 'Bodhi Rook',\n",
    " 'C-3PO',\n",
    " 'Captain Phasma',\n",
    " 'Cassian Andor',\n",
    " 'Chewbacca',\n",
    " 'Dark Sidious',\n",
    " 'Darth Maul',\n",
    " 'Darth Vader',\n",
    " 'Finn (FN-2187)',\n",
    " 'General Grievous',\n",
    " 'General Hux',\n",
    " 'Grand Moff Tarkin',\n",
    " 'Greedo',\n",
    " 'Han Solo',\n",
    " 'Jabba the Hutt',\n",
    " 'Jango Fett',\n",
    " 'Jar Jar Binks',\n",
    " 'Jyn Erso',\n",
    " 'K-2SO',\n",
    " 'Kenobi',\n",
    " 'Kylo Ren',\n",
    " 'Lando Calrissian',\n",
    " 'Luke Skywalker',\n",
    " 'Mace Windu',\n",
    " 'Maz Kanata',\n",
    " 'Nien Nunb',\n",
    " 'Obi-Wan',\n",
    " 'Orson Krennic',\n",
    " 'Padme Amidala',\n",
    " 'Poe Dameron',\n",
    " 'Princess Leia Organa',\n",
    " \"Qi'ra\",\n",
    " 'Qui-Gon Jinn',\n",
    " 'R2-D2',\n",
    " 'Rey',\n",
    " 'Rose Tico',\n",
    " 'Saw Gerrera',\n",
    " 'Supreme Leader Snoke',\n",
    " 'Tobias Beckett',\n",
    " 'Vice-Admiral Holdo',\n",
    " 'Watto',\n",
    " 'Wedge Antilles',\n",
    " 'Wicket W. Warrick',\n",
    " 'Yoda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd525a4-3dc8-45ab-9e7f-077aece2256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "# Model must be on the same level as this notebook \n",
    "model_ft = torch.load(\"entire_model.pt\")\n",
    "model_ft.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9be84e0-fad2-4c4b-bd9e-39526343326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = 256\n",
    "loader = transforms.Compose([transforms.Scale(imsize), transforms.ToTensor()])\n",
    "\n",
    "def image_loader(image_name: str) -> list:\n",
    "    \"\"\"\n",
    "    Load image, returns tensor.\n",
    "    image_name: path to the image file\n",
    "    return: image already preprocessed\n",
    "    \"\"\"\n",
    "    image = Image.open(image_name)\n",
    "    image = loader(image).float()\n",
    "    image = torch.autograd.Variable(image, requires_grad=True)\n",
    "    image = image.unsqueeze(0)  #this is for VGG, may not be needed for ResNet\n",
    "    return image\n",
    "\n",
    "def predict(model, img, img_show):\n",
    "    \"\"\"\n",
    "    Predicts the character in the picture and plots the image.\n",
    "    model: Pytorch model\n",
    "    img: preprocessed image to be used for inference\n",
    "    img_show: image read with cv library. It will be plotted along with the predicted category\n",
    "    return: None\n",
    "    \"\"\"\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model_ft(img)\n",
    "        prediction = int(torch.max(output.data, 1)[1].numpy())\n",
    "\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.axis('off')\n",
    "        ax.set_title('predicted: {}'.format(class_names[ prediction ]))\n",
    "        plt.imshow(img_show)\n",
    "\n",
    "        model.train(mode=was_training)\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd259c5-8877-44ad-ae73-e81c770feb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image's path, preprocess it and then predict\n",
    "# It is necessary to create a folder named 'pred' on the same level as this notebook and store the images there\n",
    "path= [path for path in os.listdir(\"pred\")\n",
    "       if not path.endswith(\".ipynb\") and not path.endswith(\".ipynb_checkpoints\")][0]\n",
    "imagen = cv.imread(os.path.join(r\"pred\",path))\n",
    "image = image_loader(os.path.join(r\"pred\",path))\n",
    "predict(model_ft, image, imagen)\n",
    "# os.remove(os.path.join(r\"pred\",path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
